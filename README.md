HIMAG Dataset & Code Release

Datasets
========

In the `./datasets/` directory, we release the following seven datasets:
* Marketing: Education (`./datasets/marketing/education/`)
* Marketing: Wellness (`./datasets/marketing/wellness/`)
* Topic Modeling: Databases (`./datasets/topic_model/Databases/`)
* Topic Modeling: Machine Learning (`./datasets/topic_model/Machine_Learning/`)
* Pokec social graph (`./datasets/social_graphs/pokec/`)
* LiveJournal social graph (`./datasets/social_graphs/livejournal/`)
* Sim-2 test data (`./datasets/sim2/`)

**Marketing datasets** were generated by processing raw data crawled from
Instagram. The raw source data is not being released with this paper. However,
we are releasing the graphs for use by the community.

**Topic Modeling datasets** were generated by processing raw data crawled from
academic publications. Again, the raw source data is not being released, but we
are releasing the graphs for public use.

The **Pokec social graph** was created by processing the raw graph made
available by the Stanford Network Analysis Project at
[snap.stanford.edu/data/soc-Pokec.html](https://snap.stanford.edu/data/soc-Pokec.html).

The **LiveJournal social graph** was also created by processing the raw graph
made available by the Stanford Network Analysis Project at
[snap.stanford.edu/data/com-LiveJournal.html](https://snap.stanford.edu/data/com-LiveJournal.html).

**Sim-2** spatial data is re-used from the Auto-HDS paper, and is transformed
into a graph (**Sim-2 Graph**). The original spatial data is available in
`./datasets/sim2/spatial/`. The data was converted to a graph using
`dist(a, b)/max_dist` as the edge weight, as explained in our paper. The graph
is available in `./datsets/sim2/graph/`.

See also the licenses at `./datasets/marketing/LICENSE` and `./datasets/topic_model/LICENSE`.


Gene DIVER 3.0
==============

TODO: add stuff

Gene DIVER 3.0 blah blah \[TODO: Add Java version\]

See also the license at `./GeneDIVER3.0/LICENSE`.


Experimental Tools
==================

In `./python` are contained all the tools we used to run experiments.

The following is required to be installed for full functionality:
* Python 3
* virtualenvwrapper (see [instructions](https://virtualenvwrapper.readthedocs.io/en/latest/install.html#basic-installation))
* Java (for Gene DIVER 3.0)
* hMETIS (see instructions at `./python/graphDataAnalysis/hmetis_README.md`)
* KaHIP (see instructions at `./python/graphDataAnalysis/kahip_README.md`)
* KaHyPar (see instructions at `./python/graphDataAnalysis/kahypar_README.md`)
* PaTOH (see instructions at `./python/graphDataAnalysis/patoh_README.md`)

To build the Python virtualenv, `cd` into `./python` in a Bash terminal, and
source the `setup.sh` script.


### Sim-2 results reproduction

Run `./python/sim2/automated_run.py` to get a list of steps to reproduce Sim-2
results.


### Social graph results reproduction

These steps are for Pokec. The process is almost identical for LiveJournal

**Step 1:** Set up staging directory

Create a directory for staging and move `soc-pokec-profiles.txt` and
`soc-pokec-relationships.txt` into it.

**Step 2:** Convert data to graph.

Run `./python/graphDataAnalysis/convert_data.py` with appropriate arguments.

**Step 3:** Stage the graph

Run `./python/graphHDS/stage_graph_for_autohds.py` with appropriate arguments.

Then, symlink the generated `pokec/experiment_name/graph.jsonl` to
`pokec/experiment_name/himag_experiment_name.json`, and symlink
`pokec/experiment_name/graph.mapping.tsv` to
`pokec/experiment_name/himag_experiment_name.mapping.tsv`.

**Step 4:** Run HIMAG

Run `./python/graphHDS/runGraphHDS2.py` with appropriate arguments.

Run `./GeneDIVER3.0/genediver64.sh` and select
`pokec/experiment_name/himag_experiment_name/graph.txt`.

**Step 5:** Stage the data for other algorithms

For the algorithms that you want to do **2k** runs for, copy their generated
directories to `<algo_name>.overclustered`.

Run `./python/graphDataAnalysis/prepare_algos.py` with appropriate arguments.

**Step 6:** Run other algorithms

The previous step will have printed commands to run the other algorithms. Run
them.

**Step 7:** Run measurements

Run `./python/graphDataAnalysis/run_measurements.py` with appropriate
arguments.

**Step 7:** Generate plots (optional)

Run `./python/graphDataAnalysis/ari_plot.py` with appropriate arguments.

### Topic and Marketing results reproduction

The labels were already generated based on clusterings for the algorithms, so
generating measurements does not involve running the algorithms again. The
tools for dealing with this data are in `./python/labeling/`.


See also the license at `./python/LICENSE`.
